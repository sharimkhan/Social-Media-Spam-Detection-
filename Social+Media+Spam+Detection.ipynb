{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection in Social Media Using Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social media spam from malicious content to unsolicited promotion is an issue that plagues all social networks. But it is a problem that Machine Learning can help solve. In this project, Naïve Bayes, Support Vector Machine, and Random Forest machine learning paradigms are compared, analyzed, and implemented to help combat this spam issue on the social network, Twitter. With reports of nearly 48 million bots on Twitter out of 319 million monthly active users in March 2017, the issue is quite rampant. The models will be trained on a labeled dataset of tweets and user data gathered and collected using Tweepy. The features of the data analyzed are the tweet itself and the number of followers and followings of the user. The labeled dataset will include a variety of spam messages and style in order to acknowledge that different spammers have varying techniques from spammer to spammer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data:\n",
    "I began this project on a labeled dataset of text messages found [here](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset labels spam messages as \"spam\" and non-spam as \"ham\". The labels were converted to 0 for \"ham\" and 1 for \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_table(\"/filelocation/SMSSpamCollection\")\n",
    "df.head()\n",
    "df[df.columns[0]] = df[df.columns[0]].map({'ham':0, 'spam':1})\n",
    "df.columns = ['label', 'sms_message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splits\n",
    "In order to prepare each algorithm the data needs to be split into a training and a testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], df['label'], random_state=1)\n",
    "training_data = count_vector.fit_transform(X_train)\n",
    "testing_data = count_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "All the algorithms used in this project will be evaluated in the categories of:\n",
    "#### Accuracy:\n",
    "The measurement of how often the correct prediction is made. It is the ratio of correct predictions to the total number of predictions. \n",
    "#### Precision:\n",
    "The proportion of messages classified as spam that were actually spam. The ratio of True Positives/Total Positives\n",
    "#### Recall:\n",
    "The proportion of messages that were spam that were accurately labeled as spam. The ratio of True Positives/(True Positives + False Negatives)\n",
    "#### F1 Score: \n",
    "The F1 score is the weighted average of the precision and recall, where the best value is at 1 and the worst at 0. \n",
    "F1 = 2* (precision * recall)/(precision + recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "The first paradigm I will be testing is Naive Bayes. Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of independence between every pair of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data,y_train)\n",
    "nbpredictions = naive_bayes.predict(testing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy score: ', format(accuracy_score(y_test,nbpredictions)))\n",
    "print('Precision score: ', format(precision_score(y_test,nbpredictions)))\n",
    "print('Recall score: ', format(recall_score(y_test,nbpredictions)))\n",
    "print('F1 score: ', format(f1_score(y_test,nbpredictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score:  0.9834888729361091\n",
    "Precision score:  0.9555555555555556\n",
    "Recall score:  0.9197860962566845 \n",
    "F1 score:  0.9373297002724795 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine \n",
    "Support Vector Machines are based on the concept of decision planes that define decision boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(probability=True, C=1000)\n",
    "clf.fit(training_data,y_train)\n",
    "svmpredictions = clf.predict(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy score: ', format(accuracy_score(y_test,svmpredictions )))\n",
    "print('Precision score: ', format(precision_score(y_test,svmpredictions )))\n",
    "print('Recall score: ', format(recall_score(y_test,svmpredictions )))\n",
    "print('F1 score: ', format(f1_score(y_test,svmpredictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Accuracy score:  0.9870782483847811\n",
    "Precision score:  0.9941520467836257\n",
    "Recall score:  0.9090909090909091\n",
    "F1 score:  0.9497206703910615"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
